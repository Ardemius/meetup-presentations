= Jeudi 11:15 / 12:00 - 10 erreurs à éviter avec Spark
Thomas SCHWENDER <https://github.com/ardemius[@ardemius]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ../images
:source-highlighter: highlightjs
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
//:toclevels: 3
// To turn off figure caption labels and numbers
:figure-caption!:

toc::[]

Par *Juergen Hoeller* (co-founder of the Spring Framework open source project), *Josh Long* (Spring Developer Advocate at Pivotal). +
https://cfp.devoxx.fr/2018/talk/ZYX-2364/Reactive_Spring[Descriptif de la conférence sur le site du CFP de Devoxx] +
icon:tags[] Key words : Reactive programming, Spring Boot, Spring 5, Kotlin, Spring Cloud

ifdef::env-github[]
https://www.youtube.com/watch?v=RJpbuqsoLPo[vidéo de la présentation sur YouTube]
endif::[]
ifdef::env-browser[]
video::RJpbuqsoLPo[youtube, width=640, height=480]
endif::[]

== Overview

====
Spring Framework 5 is here ! +
It introduces the Spring developer to a growing world of support for reactive programming across the Spring portfolio, starting with a new Netty-based web runtime, component model and module called Spring WebFlux, and then continuing to Spring Data Kay, Spring Security 5.0, Spring Boot 2.0 and Spring Cloud Finchley.

Sure, it sounds like a lot, but don't worry! join us, your guides, Spring co-founder and Spring Framework lead Juergen Hoeller and Spring developer advocate Josh Long, and we'll explore the wacky world of Reactive Spring together.
====

== Notes

.L'architecture de Spark
image:photo1.jpg[]

=== RDD vs Dataframe vs Dataset

* RDD permet d'opérer directement sur les partitions
	** programmation fonctionnelle préconisée
	** Attention ! aucune optimisation appliquée par Spark avec les RDD

* DataFrame
	** optimisations appliquées par Spark
	** à chaque calcul, Spark essaye de réduire le data shuffle
	** pas de remontée d'erreurs à la compil, tout au runtime (hélas ! donc compliqué à débugger)

* DataSet

=== Data sérialisation Format

* Par défaut, avec les RDD, c'est la sérialisation de Java qui est utilisée -> il est préférable d'utiliser Kryo
	** plus compact et plus rapide (x10) avec Kryo
	** pas la peine si on utliser des DataFrame et DataSet (sérialisation avec Tungsten)

=== Storage formats

image:photo2.jpg[]

* éviter les formats text (csv, json), mais préférer les binaires (Parquet, Avro, Protobuf)
	** à choisir en fonction de son use case




