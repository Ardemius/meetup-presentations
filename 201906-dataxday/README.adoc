= DataXDay 2019
Thomas SCHWENDER <https://github.com/ardemius[@ardemius]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ./images
:source-highlighter: highlightjs
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
:toclevels: 1
// To turn off figure caption labels and numbers
:figure-caption!:

toc::[]

Site du salon : https://dataxday.fr/

== Keynote 1 : La confiance entre les humains et les donn√©es

Par Caroline Goulard, CEO Dataveyes

Sites int√©ressants de visualisation de donn√©es :

* architectureofradio.com
* Ville vivante
* Behind the Banner

-> Il faut rendre "visible" et compr√©hensible la data √† tout un chacun.
C'est √©galement valable pour *l'algorithmie* qui g√©n√®re certaines donn√©es / stats.

Cas du sulfureux compteur Linky, qui est un gros collecteur de data (consommation, pr√©sence chez soi, etc.), pour lequel tr√®s peu de comm est faite sur ce que l'on pourrait faire avec ces donn√©es. +
Avec plus d'infos sur les possibilit√©s, r√©elles et utiles, de l'usage de ces data, le consommateur / client serait sans doute moins m√©fiant sur le produit.

== Keynote 2 : Database infrastructure at Instagram scale

Par Micha√´l Figui√®re, software engineer, Facebook

== From Jupyter notebooks to Machine Learning in production

By Pauline Nicolas / Th√©o Bontempelli, Data Scientist / Data Engineer - Deezer

=== Abstract

====
Chez Deezer, le Machine Learning (apprentissage automatis√©) est au c≈ìur de nombreux aspects de l‚Äôapplication. +
Au sein de l‚Äô√©quipe analytics, nous travaillons sur diff√©rentes t√¢ches telles que la pr√©diction et la pr√©vision d‚Äô√©v√®nements, dans le but de fournir des retours utiles pour les √©quipes produit et business. +
Au cours des discussions avec ces √©quipes, nous avons r√©alis√© que pour beaucoup de projets, l‚Äôacc√®s en temps r√©el aux pr√©dictions de nos mod√®les repr√©sentait un r√©el int√©r√™t. +
Ce constat nous a donc amen√©s √† exploiter l‚Äôensemble des analyses r√©alis√©es dans nos notebooks afin de d√©ployer nos algorithmes en production sous Spark.

Afin de r√©ussir au mieux ces migrations, nous avons mis en ≈ìuvre un certain nombre de proc√©d√©s, de la data architecture review √† l‚Äôimpl√©mentation des mod√®les en Scala Spark. +
Pour illustrer cela, nous vous parlerons de notre retour d‚Äôexp√©rience sur la pr√©diction du churn √† Deezer et nous vous pr√©senterons comment les data scientists et les data engineers ont travaill√© ensemble √† la r√©ussite de ce projet.
====

=== Notes

2 √©v√®nements importants concernant un user chez Deezer :

* conversion : quand un user d√©cide de s'abonner (payer) pour acc√©der au contenu premium
* *churn* : quand un user d√©cide d'arr√™ter son abonnement

Ont cherch√© √† mod√©liser le churn via apprentissage supervis√©.

.mod√©lisation du churn
image:jupyter-to-ml-in-prod_01.jpg[]

.mise en place d'un process / organisation pour la d√©termination du mod√®le de machine learning du churn
image:jupyter-to-ml-in-prod_02.jpg[]

-> travail en commun entre data scientist, data engineer ET un avis ext√©rieur √† l'√©quipe (data engineer d'une autre √©quipe)

TODO : r√©cup√©rer le workflow de la mise en prod

Ils sont pass√©s de Scikits Learn, en Python, √† Spark ML, ce qui n'est pas, de leur exp√©rience, une migration des plus faciles.

.conclusion
image:jupyter-to-ml-in-prod_03.jpg[]

-> Conclusion : la marche est haute entre exploration et mise en production +
Une bonne organisation (humaine est essentielle)

== Confident Data migration: automatic regression testing

Par Thomas Franquelin, Staff Software Engineer - Contentsquare

=== Abstract

====
In the course of 3 years, ContentSquare changed its main data store twice! We first moved from Redshift to Elasticsearch, then to Clickhouse. +
During this time, we had to deal with a vast increase in data volume, and support more and more features. How did we ensure that we didn‚Äôt break our application in the process? +
We‚Äôll talk about a simple way to achieve this by replaying production load to legacy and new systems at the same time, and studying statistical differences between the two in order to pinpoint regressions. +
We‚Äôll see that this method also makes from a coarse-grained, but fairly realistic load testing.
====

=== Notes

ContentSquare migrated twice in a row: Amazon Redshift -> Elastic -> ClickHouse

image::confident-data-migration_01.jpg[]

* Amazon Redshift : great flexibility, but poor performances
* Elastic : good performances, but very expensive
* CLickHouse :

.Tools at our disposal to test our migration
image:confident-data-migration_02.jpg[]

-> in orange, 2 comparators

.focus on the comparators
image:confident-data-migration_03.jpg[]

.Prod Request Comparator
.image:confident-data-migration_04.jpg[]

What if the legacy system is wrong ?

* best solution is to fix the problem in the legacy system
* other approach, sad but realistic: keep the bug, do the migration, and fix the bug later +
-> it allows to avoid differences during the comparison legacy <> new system

.The way to iterate until everything is good
image:confident-data-migration_05.jpg[]

== How to leverage the Apache Kafka Ecosystem to productionize Machine Learning

By Kai Waehner, Technology Evangelist - Confluent

=== Abstract

====
This talk shows how to productionize Machine Learning models in mission-critical and scalable real time applications by leveraging Apache Kafka as streaming platform. +
The talk discusses the relation between Machine Learning frameworks such as TensorFlow, DeepLearning4J or H2O and the Apache Kafka ecosystem.

A live demo shows how to build a mission-critical Machine Learning environment leveraging different Kafka components: Kafka messaging and Kafka Connect for data movement from and into different sources and sinks, Kafka Streams for model deployment and inference in real time, and KSQL for real time analytics of predictions, alerts and model accuracy.
====

=== Notes

.some Use Cases
image:kafka-to-productionize-ml_01.jpg[]

.What does allow Machine Learning here?
image:kafka-to-productionize-ml_02.jpg[]

.Hidden Technical Debt in Machine Learning systems
image:kafka-to-productionize-ml_03.jpg[]

Several (famous) companies already solved this kind of problematics through *custom ML frameworks*: Netflix / Uber / PayPal +
TODO: a good slide to retrieve at this point

.Confluent Business value per Use Case
image:kafka-to-productionize-ml_04.jpg[]

.Infrastructure for ML using Kafka
image:kafka-to-productionize-ml_05.jpg[]

.Ingestion in the Data Store
image:kafka-to-productionize-ml_06.jpg[]

.Model training using a Data Store
image:kafka-to-productionize-ml_07.jpg[]

A log "never" forgets -> you can branch different consumers at differents points on the log

== How to use Kafka to transform a batch pipeline into a real time one?

Par St√©phane Mareek, CEO - DataCumulus

=== Abstract

====
Apache Kafka has real-time capability and everyone knows that! The real challenge facing engineers comes from re-designing the existing data pipelines from batch to real-time.

In this talk, we will do a case study on how to build an end-to-end real-time data pipeline by building four micro-services on top of Apache Kafka. +
It will give you insights into the Kafka Producer API, Avro and the Confluent Schema Registry, the Kafka Streams High-Level DSL, and Kafka Connect Sinks.
====

=== Notes

St√©phane est un expert sur Kafka, auteur de plusieurs articles sur le sujet, et d'un cours sur Udemy

Tout le code du talk et de la d√©mo est disponible sur GitHub

.New Real Time pipeline using Kafka
image:kafka-batch-to-tr_01.jpg[]

-> d√©mo compl√®te et tr√®s int√©ressante (Kafka Connect + Streams + schema registry)

[NOTE]
====
* Kafka "Conduktor" to have a look at
====

image::kafka-batch-to-tr_02.jpg[]

== L'incroyable efficacit√© de l'unification des logs !

Par Jonathan Winandy, Dirigeant fondateur - Univalence

=== Abstract

====
Avez-vous d√©j√† rencontr√© un bug vraiment prise de t√™te ? Avez-vous souhait√© pouvoir juste faire un ctrl-Z ?

Bien que les micro-services soient plus complexes √† exploiter que leurs homologues monolithiques, ils laissent place √† des architectures qui nous permettent d'analyser et de corriger les erreurs du pass√© et nous √©vitent des surprises dans le futur.

Apr√®s un rappel rapide sur le tracing distribu√©, nous verrons comment avec un Kafka r√©cent et Jaeger on peut construire un syst√®me complet avec:

- l'unification et la compression des donn√©es,
- l'analyse de la cause et de la source des bugs et des effets,
- le ``voyage dans le temps``.

Aucune connaissance pr√©alable de ``Dapper`` et du fonctionnement des cabines t√©l√©phoniques sont requises ! üòâ
====

=== Notes

Jonathan a cr√©√© Univalence pour "s'y retrouver" dans toutes les briques technologiques des stack "Big Data" actuelles. +
(Jonathan a √©t√© dev web, avant de passer sur la Data √† une √©poque o√π il y avait beaucoup moins de technos √† conna√Ætre)

Leur job : rattraper les structures applicatives pas adapt√©es √† la collecte de la Data +
image:unification-logs_01.jpg[]

.Evolution of concurrency
image::unification-logs_02.jpg[]

-> On a jamais eu *vraiment* de concurrence jusqu'il y a peu... +
Et en tr√®s tr√®s peu de temps, √ßa nous est tomb√© dessus du fait de l'√©volution des technos pour g√©rer la "Big" Data.

image::unification-logs_03.jpg[]

-> en graphique sur le screen pr√©c√©dent, la carto d'une request Uber rebondissant de service en service.

image::unification-logs_04.jpg[]

-> Le "classique" :

* Quand on a un probl√®me, il y a des chances que Google l'ait aussi
* Google met ses chercheurs dessus, et publie un papier
* 2 ans plus tard, on a une impl√©mentation Open Source

-> Cas de Dapper (Google), qui va donner naissance √† *Zipkin*, qui va derni√®rement *√™tre supplant√© par Jaeger*

NOTE: On ne parle plus de tra√ßabilit√©, mais "d'observabilit√©"

Derni√®rement, annonce √† la KubeCon, OpenCensus et OpenTracking vont fusionner et devenir *OpenTelemetry*.

.Qu'est-ce qu'une trace ?
image:unification-logs_05.jpg[]
image:unification-logs_06.jpg[]

.Logging vs tracing
image:unification-logs_07.jpg[]

.Architecture de tracing
image:unification-logs_08.jpg[]

.Architecture de tracing avec Kakka
image:unification-logs_09.jpg[]

.Jaeger UI
image:unification-logs_10.jpg[]
image:unification-logs_11.jpg[]

image::unification-logs_12.jpg[]

-> *Cas de mon√©tisation de la data* (un classique) : en exposant la data sous forme d'API, on peut dire via le tracing combien de fois le service A a appel√© le service B

Le graphe des appels inter-services permet de cr√©er une *documentation du runtime*.

.Unification des logs
image:unification-logs_13.jpg[]

-> soyons clairs, le *bus async* du screen pr√©c√©dent est bien entendu Kafka.

image::unification-logs_14.jpg[]

-> Le passage en async via Kafka des logs posent quelques probl√®mes √† OpenTracing, mais on s'en sort quand m√™me.

.Avantages de joindre les √©v√®nements et les traces
image::unification-logs_15.jpg[]

-> joindre les 2 va permettre de cr√©er des logs beaucoup plus courts. +
Ex : pour un probl√®me de mail invalide, plut√¥t que de logger "nous avons rencontr√© blabla, un probl√®me de blabla avec le mail blabla", on peut se contenter de logger "mail invalide" car on a le mail dans l'√©v√®nement

.Principe 3 : identifier les places de calculs (on lie le log avec le code associ√©)
image:unification-logs_16.jpg[]
image:unification-logs_17.jpg[]

.Conclusion
image:unification-logs_18.jpg[]

-> TRES BONNE CONF ! +
A garder sous le coude en cas de probl√®me de logging / tracing

=== Q&A :

Un rappel : une BDD a 3 caract√©ristiques :

* un syst√®me de persistence
* un moteur d'indexation
* un syst√®me de requ√™tage

== Incremental Data Architecture

Par Walid Haouari, Data Engineer - Xebia

=== Abstract

====
Le design d'architecture data n'a jamais √©t√© chose facile. +
On rencontre souvent des risques d'inadaptation au besoin, des faibles performances, des blocages paresseux voir un accomplissement partiel des objectifs de d√©part. +
Dans la plupart du temps, ces probl√©matiques sont directement li√©es √† un manque ou une mauvaise gestion des resources.

L'Incremental Software Architecture est une m√©thode de conception avanc√©e qui va permettre d'outrepasser ces risques tout en garantissant des syst√®mes √©lastiques, efficaces et rentables.

Nous allons voir ensemble comment adopter cette approche favorisant la productivit√©, √©tape par √©tape, le tout dans un contexte Data.
====

=== Notes

.Le talk se concentre sur la gestion des *ressources* :
image:incremental-architecture_01.jpg[width=600]

-> et g√©n√©ralement pas de budget...

.D√©finition de l'architecture incr√©mentale
image:incremental-architecture_02.jpg[width=600]
image:incremental-architecture_03.jpg[width=600]

.C√¥t√© infrastructure
image:incremental-architecture_04.jpg[width=800]

.C√¥t√© Dev
image:incremental-architecture_05.jpg[width=800]

.Probl√©matique des architectures Data
image:incremental-architecture_06.jpg[width=800]

-> La *complexit√© des architectures Data* vient principalement de la multiplicit√© des technos de la stack, et du couplage fort souvent existant entre ces derniers. +
-> De plus, on a *souvent des probl√®mes avec le mod√®le de donn√©es*, qui est rarement pens√© pour √™tre incr√©mental.

.M√©thode d'architecture incr√©mentale : l'it√©ration
image:incremental-architecture_07.jpg[width=800]

-> on cherche √† *minimiser la perte d'une it√©ration* √† l'autre

.step "√©tat des lieux"
image:incremental-architecture_08.jpg[width=800]

.step "Design"
image:incremental-architecture_09.jpg[width=800]
image:incremental-architecture_10.jpg[width=800]

==== D√©mo

* tout est dans un environnement AWS
	** Kinesis : messaging syst√®me

.Besoin et contraintes
image:incremental-architecture_11.jpg[width=800]

.Architecture cible
image:incremental-architecture_12.jpg[]

.It√©ration 1
image:incremental-architecture_13.jpg[]

.It√©ration 2 : on forme √† Spark nos 2 devs Python
image:incremental-architecture_14.jpg[width=800] +
image:incremental-architecture_15.jpg[]

.It√©ration 3 : on peut maintenant introduire Spark
image:incremental-architecture_16.jpg[width=800] +
image:incremental-architecture_17.jpg[]

.It√©ration 4
image:incremental-architecture_18.jpg[]

.It√©ration finale
image:incremental-architecture_19.jpg[]

==== Conseils / take away

* √©viter les "mutations" d'architecture -> ce qui pourrait casser de pr√©c√©dents incr√©ments
	** garder √† l'esprit que l'architecture "cible" de laquelle nous partons n'est *PAS* une architecture finale, immuable
* don't mess with security !
* mettre des indicateurs et les monitorer : dimension co√ªts, charges, scalabilit√© +
Ex : mise en place d'un scanner de vuln√©rabilit√©
* conna√Ætre la valeur de l'incr√©ment avant l'impl√©mentation
* utiliser la puissance des outils scalables *seulement quand il le faut !*
* prendre la qualit√© en consid√©ration

-> Le talk avait vraiment trait sur la mise en place d'un *process* d'architecture incr√©mentale.

== Quelle strat√©gie de test pour vos applicatifs de machine learning ?

Par Victor Landeau, ing√©nieur Machine Learning - OUI.sncf

=== Abstract

====
Chez Oui.sncf, cela fait maintenant plusieurs ann√©es que nous utilisons des algorithmes de Machine Learning dans certains de nos applicatifs en production. Mais cela n'est pas sans poser de probl√®me, notamment du fait du caract√®re non-d√©terministe de ces approches.

En effet, comment peut-on d√©velopper sereinement des applicatifs dont les sorties attendues ne sont pas connues par avance ?

Pour r√©pondre √† cette probl√©matique, nous avons d√©velopp√© notre propre strat√©gie de test, adapt√©e au monde incertain du Machine Learning. Cette approche se base sur trois grandes couches de tests que nous vous d√©taillerons dans ce Talk.
====

=== Notes

Oui.sncf est le 1er site de e-commerce en France

* Pr√©dire le futur en fonction du pass√©

.Les phases de l'apprentissage supervis√©
image::strategie-tests-ml_01.jpg[]

-> Ce Machine Learning ne tient pas sur 1 seul ordinateur !

.Tests unitaires avec Given / When / Then
image:strategie-tests-ml_02.jpg[]

.Et TDD pour bien le faire
image:strategie-tests-ml_03.jpg[]

.Tests d'int√©gration
image:strategie-tests-ml_04.jpg[]

.Il y a aussi les tests dit "black-box"
image:strategie-tests-ml_05.jpg[]

Attention ! Lancez tous les tests de bout en bout *prend du temps* ! +
-> besoin d'optimisation

.En conclusion sur les tests
image:strategie-tests-ml_06.jpg[]

Gardez en m√©moire que l'environnement est changeant ! +
A l'arriv√©e d'un nouvel acteur (ou autre), notre comportement peut changer. +
-> Dans ces cas, un r√©-entra√Ænement est n√©cessaire

Pour conclure :

image:strategie-tests-ml_07.jpg[] +
image:strategie-tests-ml_08.jpg[]

== Give meaning to 100 billion analytics events a day, analytics at Teads

Par Alban Perillat-Merceroz, Software Engineering Manager - Teads

=== Abstract

====
This talk showcases how we built a platform that is capable of ingesting and transforming a stream of Billions of events a day using BigQuery, and how we use and abuse Redshift to deliver self-served, tailored views to many data visualisation clients and web apps.
====

=== Notes

.Teads and its global media platform
image:analytics-at-teads_01.jpg[]

image::analytics-at-teads_02.jpg[]

-> Only 10 people to handle the data pipeline

Again, a solution using *Kafka* !

.Teads "quick" architecture
image:analytics-at-teads_03.jpg[]

Tracker split into 2:

* *tracker collector*: very straight forward, with no dependency on any database
* *tracker hydrator*: dependencies on databases are here +
*Flink* is used here to perform *stateful processes*.

image::analytics-at-teads_04.jpg[]

.The rollup job (Data Warehouse part, using *BigQuery SQL*) is as easy as this
image:analytics-at-teads_05.jpg[]

For their Datamart, they *move from BigQuery to IBM Redshift*.

.Redshift (option 3) chosen instead BigQuery
image:analytics-at-teads_06.jpg[]

* *BigQuery*: minimum latency of 5 sec per query +
-> they wanted *subsecond* latency
* *BigQuery*: concurrency limits

[NOTE]
====
IEE is a proprietary fork of MySQL, modified for analytics (column-oriented). +
Although it was fine to use IEE to serve dashboards with Chartio (SaaS visualization app, that we use internally for Business Intelligence), we were reaching its limits, in terms of pricing and scalability.
====

For the Internal Data Visualisation, they chose *ChartIO*

.Redshift as a solution
image:analytics-at-teads_07.jpg[]

.Redshift key learnings
image:analytics-at-teads_08.jpg[]

.For orchestration and scheduling
image:analytics-at-teads_09.jpg[]

-> Not Airflow, but "just" Jenkins plus an internal tool ("JobHistory")

.Final architecture for Teads Data pipeline
image:analytics-at-teads_10.jpg[]

-> But that's still not enough to handle 100 billion events

.90% percent of the data is trashed ! (*sampling*)
image::analytics-at-teads_11.jpg[]

[NOTE]
====
* they replaced nearly all their Scala / Spark code by BigQuery SQL one
* They mainly moved from AWS to GCP (but not totally)
====

-> Interesting talk for the description of their complete stack

.Ressources
image:analytics-at-teads_12.jpg[]

=== Q&A

* For the datamart, everything is denormalized
	** a datamart is immutable
* all the tracker process is less than 1 sec long (? for what ? But it seems to be fast)

=== Resources

J'ai trouv√© 2 articles de blog des speakers d√©crivant ce talk :

* https://medium.com/teads-engineering/give-meaning-to-100-billion-analytics-events-a-day-d6ba09aa8f44 : +
2018/04/03, ce "vieil" article d√©crit leur pipeline d'ingestion, centr√© sur BigQuery comme data warehouse. +
Comme il est expliqu√© :
____
[...] we described our *Analytics data ingestion pipeline*, with BigQuery sitting as our data warehouse. However, having our analytics events in BigQuery is not enough. Most importantly, data needs to be served to our end-users.
____

* https://medium.com/teads-engineering/give-meaning-to-100-billion-events-a-day-part-ii-how-we-use-and-abuse-redshift-to-serve-our-data-bc23d2ed3e07 : +
2019/02/26, cet article plus r√©cent explique leur passage √† Redshift pour stocker leur data marts.

== The internals of stateful stream processing in Spark Structured Streaming

Par Jacek Laskowski, Freelance IT Consultant +
-> Jacek est un expert international reconnu sur *Spark* et *Kafka*.

=== Abstract

====
Let's talk about state management in Spark Structured Streaming.

During this talk you will learn the streaming concepts that are particularly relevant for stateful stream processing in Structured Streaming, e.g. watermark and output modes, but also GroupState and GroupStateTimeout. +
We will be exploring simple stateful processing (with groupBy operator) and more advanced use cases with KeyValueGroupedDataset.mapGroupsWithState and the most advanced KeyValueGroupedDataset.flatMapGroupsWithState operator. +
In other words, you will learn how to use the stateful streaming API and understand the internals.
====

=== Notes

All the *slides* are in https://github.com/jaceklaskowski/spark-workshop

Jacek est l'auteur de plusieurs eBooks sur *Apache Spark*, *Spark SQL*, *Spark Structured Streaming*, *Kafka*. +
Tous sont disponibles librement sur *GitBook* : https://legacy.gitbook.com/@jaceklaskowski

TIP: Franchement, Jacek est tr√®s bon p√©dagogue, donc n'h√©sitez pas √† aller voir ses livres !

This talk is about *Apache Spark 2.4.3* and *Structured Streaming*

.About Jacek (Famous Spark, Kafka expert)
image:spark-structured-streaming_01.jpg[]

-> *Jacek is also a trainer*

.Agenda that we will NOT have to the time to fully complete...
image:spark-structured-streaming_02.jpg[]

.Structured Streaming
image:spark-structured-streaming_03.jpg[]

-> *Structured Streaming*, aka *Spark Streams* which introduces *streaming queries* +
-> some kind of similar to *batch queries in Spark SQL executed continuously*

.Stateful Stream Processing
image:spark-structured-streaming_04.jpg[]

Spark Structured Streaming can operate on 0, 1 or many rows at the same time. +
-> Whereas Kafka streams and Flink can only operate on *exactly* 1 row

image::spark-structured-streaming_05.jpg[]

.Streaming aggregation
image:spark-structured-streaming_06.jpg[]

*checkpoint locations*: the place where Spark Structured Streaming saves your states. +
Those info are saved as files.

.Physical plan
image:spark-structured-streaming_07.jpg[]

.Streaming watermark
image:spark-structured-streaming_08.jpg[]

-> To keep state for ever means that we will end with an Out Of Memory error. +
We have to do something for this problematic, which is *applying watermark to my state*.

-> Have a (big) look at Jacek demo code (URL available in his slides)

=== Q&A

.To control the number of partitions
image:spark-structured-streaming_09.jpg[]

-> The "good" number of partitions can only be found through *fine tuning*

== Conclusion et avis sur le salon

* Python devient r√©ellement un incontournable
* Et Kafka est absolument incontournable
* importance du *monitoring*
* les notebooks sont *TOUS* sur Jupyter, et sont tous remplac√©s par des solutions plus robustes lors du passage en PROD

Mes conf√©rences pr√©f√©r√©es ont √©t√© :

* link:dataxday-2019.adoc#_lincroyable_efficacit%C3%A9_de_lunification_des_logs[L‚Äôincroyable efficacit√© de l‚Äôunification des logs !]
* link:dataxday-2019.adoc#_give_meaning_to_100_billion_analytics_events_a_day_analytics_at_teads[Give meaning to 100 billion analytics events a day, analytics at Teads]

Mention sp√©ciale au talk de Jacek, link:dataxday-2019.adoc#_the_internals_of_stateful_stream_processing_in_spark_structured_streaming[The internals of stateful stream processing in Spark Structured Streaming], rien que pour lui (et les *r√©f√©rences*, *eBooks* donn√©s), jetez-y un oeil üòâ

.Hadoop, la chute
[IMPORTANT]
====
Un constat s'est encore confirm√© lors de ce salon : *la chute du framework Hadoop*. +
En lieu et place de ce dernier, on passe maintenant sur les stacks techniques des Cloud providers.

Je ne pense pas avoir 1 fois attendu parler de HDFS de tout le salon. +
Spark est bien s√ªr toujours l√†, mais car le framework a r√©ussi √† √©voluer et √† g√©rer d'autres syst√®mes de stockage de donn√©es.
====

== Ressources

* Toutes les vid√©os sont sur le site du salon : https://dataxday.fr/videos-slides-2019/








